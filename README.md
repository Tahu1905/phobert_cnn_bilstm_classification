 Vietnamese AI-Text Detector: Hybrid PhoBERT-CNN-BiLSTM Architecture
(https://img.shields.io/badge/PyTorch-2.0+-EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)](https://pytorch.org/) (https://img.shields.io/badge/Model-PhoBERT-blue?style=for-the-badge&logo=huggingface&logoColor=white)](https://github.com/VinAIResearch/PhoBERT) ()]()

Há»‡ thá»‘ng phÃ¡t hiá»‡n vÄƒn báº£n do AI táº¡o sinh (ChatGPT, Llama, Gemini) dÃ nh riÃªng cho tiáº¿ng Viá»‡t, sá»­ dá»¥ng kiáº¿n trÃºc lai ghÃ©p tiÃªn tiáº¿n giá»¯a Transformer, CNN vÃ  BiLSTM.

ğŸ“– Giá»›i Thiá»‡u (Introduction)
Trong bá»‘i cáº£nh bÃ¹ng ná»• cá»§a Generative AI, viá»‡c phÃ¢n biá»‡t ná»™i dung do con ngÆ°á»i viáº¿t vÃ  mÃ¡y táº¡o ra trá»Ÿ thÃ nh má»™t thÃ¡ch thá»©c lá»›n. Dá»± Ã¡n nÃ y giá»›i thiá»‡u má»™t phÆ°Æ¡ng phÃ¡p tiáº¿p cáº­n State-of-the-Art (SOTA) cho tiáº¿ng Viá»‡t, káº¿t há»£p sá»©c máº¡nh hiá»ƒu ngá»¯ nghÄ©a cá»§a PhoBERT vá»›i kháº£ nÄƒng trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng cá»¥c bá»™ cá»§a CNN vÃ  kháº£ nÄƒng náº¯m báº¯t chuá»—i thá»i gian cá»§a BiLSTM.

MÃ´ hÃ¬nh Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ phÃ¡t hiá»‡n cÃ¡c dáº¥u hiá»‡u tinh vi cá»§a vÄƒn báº£n mÃ¡y: sá»± láº·p láº¡i cáº¥u trÃºc (structural repetition), Ä‘á»™ trÃ´i cháº£y báº¥t thÆ°á»ng (unnatural fluency) vÃ  cÃ¡c máº«u thá»‘ng kÃª (statistical patterns) mÃ  máº¯t thÆ°á»ng khÃ³ nháº­n biáº¿t.

ğŸ§  Kiáº¿n TrÃºc Há»‡ Thá»‘ng (System Architecture)
MÃ´ hÃ¬nh PhoBERT-CNN-BiLSTM hoáº¡t Ä‘á»™ng dá»±a trÃªn luá»“ng xá»­ lÃ½ dá»¯ liá»‡u phá»©c há»£p:

Input Processing: VÄƒn báº£n Ä‘Æ°á»£c chuáº©n hÃ³a (Unicode NFC), lÃ m sáº¡ch (loáº¡i bá» cÃ´ng thá»©c toÃ¡n, trÃ­ch dáº«n) vÃ  phÃ¢n Ä‘oáº¡n tá»« (Word Segmentation) báº±ng VnCoreNLP.

PhoBERT Embedding Fusion:

Thay vÃ¬ chá»‰ sá»­ dá»¥ng lá»›p cuá»‘i cÃ¹ng, chÃºng tÃ´i ná»‘i (concatenate) 4 lá»›p áº©n cuá»‘i cÃ¹ng cá»§a PhoBERT.

Táº¡o ra vector biá»ƒu diá»…n siÃªu giÃ u thÃ´ng tin vá»›i kÃ­ch thÆ°á»›c 3072 chiá»u (768 x 4).

Parallel Feature Extraction:

NhÃ¡nh CNN: Sá»­ dá»¥ng cÃ¡c bá»™ lá»c kÃ­ch thÆ°á»›c `` Ä‘á»ƒ báº¯t cÃ¡c máº«u n-gram cá»¥c bá»™.

NhÃ¡nh BiLSTM: QuÃ©t toÃ n bá»™ chuá»—i vÄƒn báº£n theo hai chiá»u Ä‘á»ƒ náº¯m báº¯t ngá»¯ cáº£nh toÃ n cá»¥c.

Fusion & Classification:

Káº¿t há»£p Ä‘áº·c trÆ°ng tá»« hai nhÃ¡nh.

Äi qua cÃ¡c lá»›p Fully Connected vá»›i Dropout Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n xÃ¡c suáº¥t (Human vs AI).

ğŸ“Š Dá»¯ Liá»‡u & Hiá»‡u NÄƒng (Dataset & Performance)
Dá»± Ã¡n sá»­ dá»¥ng bá»™ dá»¯ liá»‡u ViDetect vÃ  cÃ¡c nguá»“n dá»¯ liá»‡u khoa há»c ná»™i bá»™ (train_new.tsv) Ä‘á»ƒ huáº¥n luyá»‡n.

Káº¿t quáº£ thá»±c nghiá»‡m cho tháº¥y mÃ´ hÃ¬nh vÆ°á»£t trá»™i hÆ¡n so vá»›i viá»‡c chá»‰ sá»­ dá»¥ng PhoBERT hoáº·c BiLSTM Ä‘Æ¡n láº» tá»« 2-5%.

ğŸ› ï¸ CÃ i Äáº·t & Sá»­ Dá»¥ng (Installation & Usage)
YÃªu cáº§u há»‡ thá»‘ng
Python 3.7+

CUDA (GPU) Ä‘Æ°á»£c khuyáº¿n nghá»‹ Ä‘á»ƒ huáº¥n luyá»‡n.

RAM: 16GB+ (do vector nhÃºng kÃ­ch thÆ°á»›c lá»›n).
## ğŸš€ HÆ°á»›ng dáº«n thá»±c hiá»‡n

### BÆ°á»›c 1: Clone Repository
```bash
git clone https://github.com/Tahu1905/phobert_cnn_bilstm_classification.git
cd phobert_cnn_bilstm_classification
```
### BÆ°á»›c 2: CÃ i Ä‘áº·t thÆ° viá»‡n
```bash
pip install -r requirements.txt
#CÃ i Ä‘áº·t VnCoreNLP (Báº¯t buá»™c)
pip install py_vncorenlp
```
### BÆ°á»›c 3: Chuáº©n bá»‹ dá»¯ liá»‡u
```text
label	sentence
0	Chiá»u dÃ i nÆ°á»›c nháº£y lÃ  má»™t Ä‘áº·c trÆ°ng quan trá»ng... (Human text)
1	Trong ká»· nguyÃªn sá»‘, trÃ­ tuá»‡ nhÃ¢n táº¡o... (AI text)

Äáº·t file dá»¯ liá»‡u train_new.tsv vÃ o thÆ° má»¥c gá»‘c. Äá»‹nh dáº¡ng file:
```
### BÆ°á»›c 4: Huáº¥n luyá»‡n
```bash
python main.py

Cháº¡y lá»‡nh sau Ä‘á»ƒ báº¯t Ä‘áº§u quÃ¡ trÃ¬nh training. Há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng táº£i PhoBERT pre-trained weights.
Logs sáº½ Ä‘Æ°á»£c lÆ°u táº¡i ./log (xem báº±ng TensorBoard).

Model tá»‘t nháº¥t sáº½ Ä‘Æ°á»£c lÆ°u táº¡i saved_dict/best_model.pth.
```
### BÆ°á»›c 5: Kiá»ƒm thá»­ (Inference)
Sá»­ dá»¥ng script Ä‘Ã¡nh giÃ¡ Ä‘á»ƒ kiá»ƒm tra trÃªn vÄƒn báº£n má»›i:

ğŸ”¬ PhÃ¢n TÃ­ch Ká»¹ Thuáº­t (Technical Insights)
Táº¡i sao láº¡i ná»‘i 4 lá»›p PhoBERT?
CÃ¡c lá»›p trÃªn cÃ¹ng cá»§a Transformer thÆ°á»ng thiÃªn vá» nhiá»‡m vá»¥ pre-training (MLM), trong khi cÃ¡c lá»›p dÆ°á»›i chá»©a thÃ´ng tin ngá»¯ phÃ¡p. Viá»‡c ná»‘i 4 lá»›p giÃºp mÃ´ hÃ¬nh downstream (CNN-BiLSTM) truy cáº­p Ä‘Æ°á»£c cáº£ thÃ´ng tin ngá»¯ phÃ¡p vÃ  ngá»¯ nghÄ©a, tÄƒng Ä‘á»™ bá»n vá»¯ng (robustness) cho mÃ´ hÃ¬nh.

Táº¡i sao dÃ¹ng CNN káº¿t há»£p BiLSTM?
CNN cá»±c tá»‘t trong viá»‡c phÃ¡t hiá»‡n cÃ¡c tá»« khÃ³a hoáº·c cá»¥m tá»« "láº¡" mÃ  AI hay dÃ¹ng (vÃ­ dá»¥: cÃ¡c tá»« sÃ¡o rá»—ng, láº·p láº¡i).

BiLSTM Ä‘áº£m báº£o ráº±ng vÄƒn báº£n pháº£i cÃ³ tÃ­nh máº¡ch láº¡c vá» thá»i gian. AI Ä‘Ã´i khi viáº¿t ráº¥t trÃ´i cháº£y tá»«ng cÃ¢u nhÆ°ng tá»•ng thá»ƒ Ä‘oáº¡n vÄƒn láº¡i thiáº¿u logic cháº·t cháº½, Ä‘iá»u mÃ  BiLSTM cÃ³ thá»ƒ phÃ¡t hiá»‡n qua cÃ¡c tráº¡ng thÃ¡i áº©n.

### ğŸ“œ TrÃ­ch Dáº«n (Citation)
Náº¿u báº¡n sá»­ dá»¥ng mÃ£ nguá»“n hoáº·c Ã½ tÆ°á»Ÿng tá»« dá»± Ã¡n nÃ y, vui lÃ²ng trÃ­ch dáº«n:

### 6. Káº¿t Luáº­n vÃ  Äá»‹nh HÆ°á»›ng TÆ°Æ¡ng Lai
BÃ¡o cÃ¡o nÃ y Ä‘Ã£ trÃ¬nh bÃ y má»™t giáº£i phÃ¡p toÃ n diá»‡n cho váº¥n Ä‘á» phÃ¡t hiá»‡n vÄƒn báº£n AI trong tiáº¿ng Viá»‡t. Báº±ng cÃ¡ch káº¿t há»£p sá»©c máº¡nh cá»§a PhoBERT vá»›i kiáº¿n trÃºc CNN-BiLSTM, há»‡ thá»‘ng khÃ´ng chá»‰ Ä‘áº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c cao mÃ  cÃ²n thá»ƒ hiá»‡n sá»± bá»n vá»¯ng trÆ°á»›c cÃ¡c loáº¡i vÄƒn báº£n Ä‘áº§u vÃ o Ä‘a dáº¡ng.

Tuy nhiÃªn, cuá»™c Ä‘ua giá»¯a AI táº¡o sinh vÃ  AI phÃ¡t hiá»‡n lÃ  má»™t cuá»™c Ä‘ua khÃ´ng há»“i káº¿t. CÃ¡c hÆ°á»›ng phÃ¡t triá»ƒn trong tÆ°Æ¡ng lai bao gá»“m:

Adversarial Training: Huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i cÃ¡c vÄƒn báº£n AI Ä‘Ã£ bá»‹ lÃ m nhiá»…u (paraphrased) Ä‘á»ƒ tÄƒng kháº£ nÄƒng chá»‘ng chá»‹u trÆ°á»›c cÃ¡c ká»¹ thuáº­t lÃ¡ch luáº­t.

Model Distillation: NÃ©n mÃ´ hÃ¬nh khá»•ng lá»“ nÃ y thÃ nh phiÃªn báº£n nháº¹ hÆ¡n (vÃ­ dá»¥: sá»­ dá»¥ng PhoBERT-tiny hoáº·c DistilBERT) Ä‘á»ƒ cÃ³ thá»ƒ cháº¡y trÃªn cÃ¡c thiáº¿t bá»‹ biÃªn (Edge devices) hoáº·c trÃ¬nh duyá»‡t web.

Explainable AI (XAI): TÃ­ch há»£p cÆ¡ cháº¿ Attention Map Ä‘á»ƒ trá»±c quan hÃ³a lÃ½ do táº¡i sao mÃ´ hÃ¬nh phÃ¡n Ä‘oÃ¡n má»™t Ä‘oáº¡n vÄƒn lÃ  do AI viáº¿t (vÃ­ dá»¥: tÃ´ mÃ u cÃ¡c tá»«/cá»¥m tá»« Ä‘Ã¡ng ngá»), giÃºp tÄƒng tÃ­nh thuyáº¿t phá»¥c Ä‘á»‘i vá»›i ngÆ°á»i dÃ¹ng cuá»‘i.

Há»‡ thá»‘ng nÃ y khÃ´ng chá»‰ lÃ  má»™t cÃ´ng cá»¥ ká»¹ thuáº­t mÃ  cÃ²n lÃ  má»™t bÆ°á»›c tiáº¿n quan trá»ng trong viá»‡c báº£o vá»‡ sá»± trong sÃ¡ng vÃ  chÃ¢n thá»±c cá»§a khÃ´ng gian thÃ´ng tin tiáº¿ng Viá»‡t.

TÃ¡c giáº£ bÃ¡o cÃ¡o: NgÃ y: 02/02/2026 PhiÃªn báº£n: 1.0.0
